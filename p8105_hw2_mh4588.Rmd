---
title: "p8105_hw2_mh4588"
author: "Maggie Hsu"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse") #Import packages that will be used here
library("readxl")
library("haven")
```

# Problem 1
```{r NYC}
#Import the NYC transit dataset from the csv file as a data frame. 
nyc_subway = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") |> 
  janitor::clean_names(nyc_subway, case = "old_janitor") #Clean variable names using the clean_names function

nyc_subway = select(nyc_subway, line:entry, vending, ada) #Keep specified variables
nyc_subway |>
  mutate ( 
    entry =  ifelse(pull(nyc_subway, var="entry")=="YES",TRUE,FALSE)
     )
#Convert the "entry" variable to a logical variable where YES is True and NO is False

#Identify how many distinct stops are present 
distinct(
  select(
    nyc_subway, c(line, station_name)
    )
  )

```

The nyc_subway data describes subway stations in New York City through what lines the stations are part of, their names, longitude and latitude coordinates, whether there is an entry or not, entry types, whether there is vending, whether the station is ADA-compliant, and the route names and numbers. After importing the raw data, the variable names were cleaned using clean_names() from the janitor package to make them more consistent. The specified variables were kept using select, and the entry variable was converted into a logical variable using the mutate and ifelse functions. The nyc_subway dataset consists of `{r}nrow(nyc_subway)` rows and `{r}ncol(nyc_subway)`columns. Here, since each individual route is a separate column, the dataset is not tidy. 

There are 465 distinct stops and `{r} sum((pull(nyc_subway, var="ada")=="TRUE"))` ADA-compliant stations in the subway system. Out of the stations without entrances, 


## Reformatting the data to make it tidy
```{r reformat}
#Format route name and number into distinct variables using pivot_longer
nyc_subway = pivot_longer(
    nyc_subway, 
    route1:route11,
    names_to = "route_name", 
    values_to = "route_number",
    values_transform = list(route_number = as.character)) 

```
After reformatting the group of "route" columns, this dataset is now tidy. `{r}` stations serve the A train while `{r}` stations out of these are also ADA compliant. 

# Problem 2
```{r trash wheel}
mr_trash_wheel <- read_excel("./data/202409 Trash Wheel Collection Data.xlsx", sheet = 1) #Read dataset and omit non-data entries

#Clean variable names from this dataset and make cases consistent
mr_trash_wheel= janitor::clean_names(mr_trash_wheel, case = "old_janitor") |>
  select(1:14)  |> #remove blank columns
  filter(is.na(dumpster)==FALSE) |> #remove non-dumpster observations
  mutate(wheel = "Mr.Trash Wheel", sports_balls = as.integer(sports_balls)) #add wheel variable which identifies which trash wheel and round sports balls to the nearest integer

#Professor Trash Wheel
prof_trash_wheel <- read_excel("./data/202409 Trash Wheel Collection Data.xlsx", sheet = 2) #Read the dataset and omit non-data entries for Professor Trash Wheel
prof_trash_wheel = janitor::clean_names(prof_trash_wheel, case = "old_janitor") |> #Clean variable names
  mutate(wheel = "Professor Trash Wheel", year = as.character(year)) |> #add wheel identifier 
  filter(is.na(dumpster)==FALSE) #remove non-dumpster observations

#Gwynnda
gwynnda <- read_excel("./data/202409 Trash Wheel Collection Data.xlsx", sheet = 3, range="A2:L66") #Read the dataset and omit any non-data entries for Gwynnda
gwynnda = select(gwynnda, 1:12)  |> #remove blank columns
  janitor::clean_names(gwynnda, case = "old_janitor") |> #clean variable names
  filter(is.na(dumpster)==FALSE)|> #remove non-dumpster observations
  mutate(wheel = "Gwynnda", sports_balls = 0, year = as.character(year)) #add wheel identifier, add a sports ball column, and convert year to character so it can be merged with the other datasets

#Merge trash wheel datasets
trash_wheels <-  bind_rows(mr_trash_wheel, prof_trash_wheel, gwynnda)#Merge all data frames into one large dataframe
```

# Analysis
The trash wheel dataset consists of `{r}nrow(trash_wheels)` observations and  `{r}ncol(trash_wheels)` variables , with key variables being which wheel has which dumpsters, the date an observation was made, the weight and volume of a collection, and what types of trash were being collected, such as cigarette butts, plastic bottles, or plastic bags.

The total weight of trash collected by Professor Trash Wheel is `r sum(pull(filter(trash_wheels, wheel=="Professor Trash Wheel"), var=weight_tons), na.rm=TRUE)` tons of trash while the total number of cigarette butts collected by Gwynnda in June of 2022 was `r sum(pull(filter(trash_wheels, wheel=="Gwynnda", month=="June", year==2022), var=cigarette_butts), na.rm=TRUE) ` butts. 

# Problem 3
```{r GBBO}
#Import all respective datasets from the bake off dataset folder
bake_off_bakers <- read_csv("./data/gbb_datasets/bakers.csv")
bake_off_bakes <- read_csv("./data/gbb_datasets/bakes.csv")
bake_off_results <- read_csv("./data/gbb_datasets/results.csv")
bake_off_viewers <- read_csv("./data/gbb_datasets/viewers.csv")

#Clean and organize each dataset 
#Bakers
bake_off_bakers = janitor::clean_names(bake_off_bakers, case = "old_janitor") #clean variable names
bake_off_bakers = mutate(bake_off_bakers, baker = strsplit(bake_off_bakers$baker_name, " .*")) #add column with just first names so it can be joined with the other tables based on name

bake_off_bakers = mutate(bake_off_bakers, baker = as.character(baker))

#Bakes
bake_off_bakes = janitor::clean_names(bake_off_bakes, case = "old_janitor") #clean variable names
bake_off_bakes = mutate(bake_off_bakes, baker=replace(pull(bake_off_bakes, var="baker"),pull(bake_off_bakes, var="baker")=='"Jo"',"Jo")) #remove quotation marks off "Jo" in the table
       
#Results
bake_off_results |>
  janitor::row_to_names(row_number = 67) |>
  na.omit(bake_off_results)
names(bake_off_results) <- bake_off_results[2,]
bake_off_results <- bake_off_results[-c(1:2),]
bake_off_results |>
  mutate(series = as.double(series))

#Viewers
#Reorganize the viewer table
bake_off_viewers <- pivot_longer(bake_off_viewers, "Series 1":"Series 10",names_to="series", values_to="viewers")
colnames(bake_off_viewers) <- c("episode","series","viewers")
bake_off_viewers = mutate(bake_off_viewers, episode = as.character(episode)) #convert to character so it can be merged with other data frames


#Merge datasets
bakers_and_bakes <- left_join(bake_off_bakers, bake_off_bakes, by=c("baker", "series"))
bakers_and_bakes = mutate(bakers_and_bakes, episode = as.character(episode), series = as.character(series)) #edit variable type to match variable types for the other table so it can be merged

#Final dataset
bake_off <- left_join(bakers_and_bakes, bake_off_results, by = c("episode","series", "baker"))

#Organize final dataset and order variables
bake_off <- bake_off[,c("series", "episode", "baker", "baker_name", "baker_age", "baker_occupation", "hometown", "signature_bake", "show_stopper", "result", "technical")]

#Export as csv
write_csv(bake_off, "bake_off.csv")
```
The most important considerations I had to make when cleaning and wrangling these datasets were how to organize the variables and observations so they could be tidy and able to be merged together into the final dataset. I noticed some common variables, such as baker, season, and episode, so I had to make sure that each individual data frame could be merged based on these columns. Additionally, I had to manage inconsistencies within the data such as Jo being labeled "Jo" in the Bakers dataframe with the quotation marks, which would have to be replaced without the quotation marks so the baker names could be joined together in the full dataset. Most of the data management involved ensuring variable types and names were consistent and did not have empty rows.

```{r star bakers}
#Create a table with the star bakers
star_bakers <- filter(bake_off, result=="STAR BAKER") #Filter to only show Star Bakers
star_bakers = mutate(star_bakers,series = as.integer(series)) #Change character to integer type so it can be filtered. 
star_bakers <- filter(star_bakers, series >= 5 & series <= 10) #Filter to only show seasons 5-10

knitr::kable(star_bakers) #Create table
```
Out of the Star Baker table, Richard Burr appears on multiple entries and appears to consistently be placed as Star Baker, winning 5 times. Although most of the bakers are from 20-40 years old, there were three Star Bakers over 60 years old: Nancy, Jane, and Marie while one of the Star Bakers (Liam) was 19 years old, which was surprising.

```{r viewership}
head(bake_off_viewers, 10)
```
The average viewership in Season 1 was `r mean(pull(filter(bake_off_viewers, series=="Series 1")), na.rm=TRUE)` while the average viewership in Season 5 was `r mean(pull(filter(bake_off_viewers, series=="Series 5")), na.rm=TRUE)`. 