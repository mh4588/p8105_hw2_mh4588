---
title: "p8105_hw2_mh4588"
author: "Maggie Hsu"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse") #Import packages that will be used here
library("readxl")
library("haven")
```

# Problem 1
```{r NYC}
#Import the NYC transit dataset from the csv file as a data frame. 
nyc_subway = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") |> 
  janitor::clean_names(nyc_subway, case = "old_janitor") #Clean variable names using the clean_names function

nyc_subway = select(nyc_subway, line:entry, vending, ada) #Keep specified variables
nyc_subway |>
  mutate ( 
    entry =  ifelse(pull(nyc_subway, var="entry")=="YES",TRUE,FALSE)
     )
#Convert the "entry" variable to a logical variable where YES is True and NO is False

#Identify how many distinct stops are present 
distinct(
  select(
    nyc_subway, c(line, station_name)
    )
  )

```

The nyc_subway data describes subway stations in New York City through what lines the stations are part of, their names, longitude and latitude coordinates, whether there is an entry or not, entry types, whether there is vending, whether the station is ADA-compliant, and the route names and numbers. After importing the raw data, the variable names were cleaned using clean_names() from the janitor package to make them more consistent. The specified variables were kept using select, and the entry variable was converted into a logical variable using the mutate and ifelse functions. The nyc_subway dataset consists of `{r}nrow(nyc_subway)` rows and `{r}ncol(nyc_subway)`columns. Here, since each individual route is a separate column, the dataset is not tidy. 

There are 465 distinct stops and `{r} sum((pull(nyc_subway, var="ada")=="TRUE"))` ADA-compliant stations in the subway system. Out of the stations without entrances, 


## Reformatting the data to make it tidy
```{r reformat}
#Format route name and number into distinct variables using pivot_longer
nyc_subway = pivot_longer(
    nyc_subway, 
    route1:route11,
    names_to = "route_name", 
    values_to = "route_number",
    values_transform = list(route_number = as.character)) 

```
After reformatting the group of "route" columns, this dataset is now tidy. `{r}` stations serve the A train while `{r}` stations out of these are also ADA compliant. 

# Problem 2
```{r trash wheel}
mr_trash_wheel <- read_excel("./data/202409 Trash Wheel Collection Data.xlsx", sheet = 1) #Read dataset and omit non-data entries

#Clean variable names from this dataset and make cases consistent
mr_trash_wheel= janitor::clean_names(trash_wheel, case = "old_janitor") |>
  select(1:14)  |> #remove blank columns
  filter(is.na(dumpster)==FALSE) |> #remove non-dumpster observations
  mutate(wheel = "Mr.Trash Wheel", sports_balls = as.integer(sports_balls)) #add wheel variable which identifies which trash wheel and round sports balls to the nearest integer

#Professor Trash Wheel
prof_trash_wheel <- read_excel("./data/202409 Trash Wheel Collection Data.xlsx", sheet = 2) #Read the dataset and omit non-data entries for Professor Trash Wheel
prof_trash_wheel = janitor::clean_names(prof_trash_wheel, case = "old_janitor") |> #Clean variable names
  mutate(wheel = "Professor Trash Wheel", year = as.character(year)) |> #add wheel identifier 
  filter(is.na(dumpster)==FALSE) #remove non-dumpster observations

#Gwynnda
gwynnda <- read_excel("./data/202409 Trash Wheel Collection Data.xlsx", sheet = 3, range="A2:L66") #Read the dataset and omit any non-data entries for Gwynnda
gwynnda = select(gwynnda, 1:12)  |> #remove blank columns
  janitor::clean_names(gwynnda, case = "old_janitor") |> #clean variable names
  filter(is.na(dumpster)==FALSE)|> #remove non-dumpster observations
  mutate(wheel = "Gwynnda", sports_balls = 0, year = as.character(year)) #add wheel identifier, add a sports ball column, and convert year to character so it can be merged with the other datasets

#Merge trash wheel datasets
trash_wheels <-  bind_rows(mr_trash_wheel, prof_trash_wheel, gwynnda)#Merge all data frames into one large dataframe
```

# Analysis
The total weight of trash collected by Professor Trash Wheel is `r sum(pull(filter(trash_wheels, wheel=="Professor Trash Wheel"), var=weight_tons), na.rm=TRUE)` tons of trash while the total number of cigarette butts collected by Gwynnda in June of 2022 was `r sum(pull(filter(trash_wheels, wheel=="Gwynnda", month=="June", year==2022), var=cigarette_butts), na.rm=TRUE) ` butts. 

# Problem 3
```{r GBBO}
#Import all respective datasets from the bake off dataset folder
bake_off_bakers <- read_csv("./data/gbb_datasets/bakers.csv")
bake_off_bakes <- read_csv("./data/gbb_datasets/bakes.csv")
bake_off_results <- read_csv("./data/gbb_datasets/results.csv")
bake_off_viewers <- read_csv("./data/gbb_datasets/viewers.csv")

bake_off <- data.frame() 
clean, tidy, and otherwise wrangle each of these datasets; check for completeness and correctness across datasets (e.g. by viewing individual datasets and using anti_join); merge to create a single, final dataset; and organize this so that variables and observations are in meaningful orders. 

kable()

```